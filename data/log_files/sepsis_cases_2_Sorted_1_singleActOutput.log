
Hyperopt trials:
tid,loss,time,params used
0, 1.064835, 1142.522314, {'batch_size': [4.824344393419887], 'dropout': [0.43994048341398956], 'learning_rate': [1.193549780622942e-05], 'lstmA_size_1': [38.905712526104665], 'lstmA_size_2_2': [72.67315954042692], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [35.1059023959782], 'shared_lstm_size': [50.99584880364182], 'word2vec_size': [546.0]}
1, 0.995886, 295.746396, {'batch_size': [4.28293216778081], 'dropout': [0.3127062119058413], 'learning_rate': [0.002859396962391843], 'lstmA_size_1': [26.268818717496536], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [24.86309397642601], 'lstmA_size_3_3': [55.94293685996099], 'n_layers': [2], 'output_dim_embedding': [105.70276515562537], 'shared_lstm_size': [11.993123400518167], 'word2vec_size': [343.0]}
2, 0.977944, 215.621932, {'batch_size': [5.449063979325999], 'dropout': [0.4275612229361673], 'learning_rate': [0.0005165698104293574], 'lstmA_size_1': [30.166729491524926], 'lstmA_size_2_2': [98.05236308270422], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [83.79882667582429], 'shared_lstm_size': [22.271774301159855], 'word2vec_size': [891.0]}
3, 0.980634, 226.080986, {'batch_size': [5.2377541653580355], 'dropout': [0.224435897989132], 'learning_rate': [0.00044881846408676573], 'lstmA_size_1': [107.37445085930798], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [123.40031650720806], 'lstmA_size_3_3': [36.13119393348234], 'n_layers': [2], 'output_dim_embedding': [11.389474059163602], 'shared_lstm_size': [53.26138838357758], 'word2vec_size': [246.0]}
4, 0.999130, 1106.389609, {'batch_size': [5.773975577419018], 'dropout': [0.445962341809433], 'learning_rate': [2.7726219802967743e-05], 'lstmA_size_1': [87.93631075444638], 'lstmA_size_2_2': [46.95663381219957], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [141.40763719246988], 'shared_lstm_size': [85.14254509023415], 'word2vec_size': [537.0]}
5, 0.999978, 1042.970340, {'batch_size': [5.132431861396805], 'dropout': [0.0686735824439153], 'learning_rate': [1.9911086675354495e-05], 'lstmA_size_1': [102.44454402595791], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [39.00872505938553], 'lstmA_size_3_3': [31.463223230977626], 'n_layers': [2], 'output_dim_embedding': [38.705893716921366], 'shared_lstm_size': [59.333107537989974], 'word2vec_size': [228.0]}
6, 0.975571, 649.799456, {'batch_size': [5.232170482936796], 'dropout': [0.4564784682057944], 'learning_rate': [0.00018402238611188695], 'lstmA_size_1': [112.84481320711195], 'lstmA_size_2_2': [31.301483959745166], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [37.87020519078725], 'shared_lstm_size': [19.132622349563952], 'word2vec_size': [977.0]}
7, 1.015185, 2663.719531, {'batch_size': [3.625698973388985], 'dropout': [0.2398516856771029], 'learning_rate': [3.256430189067019e-05], 'lstmA_size_1': [13.902916841198474], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [140.07738095004547], 'lstmA_size_3_3': [20.184431509221536], 'n_layers': [2], 'output_dim_embedding': [65.45265402273643], 'shared_lstm_size': [67.25062588337444], 'word2vec_size': [174.0]}
8, 0.987367, 1217.689146, {'batch_size': [3.3171311474539302], 'dropout': [0.21959642792555245], 'learning_rate': [0.00028673397930694495], 'lstmA_size_1': [94.72528805576884], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [130.46825553208768], 'lstmA_size_3_3': [54.426674860883466], 'n_layers': [2], 'output_dim_embedding': [50.42027554804782], 'shared_lstm_size': [13.876717653771014], 'word2vec_size': [643.0]}
9, 0.990042, 1998.712596, {'batch_size': [3.3726485863972506], 'dropout': [0.4546932997720431], 'learning_rate': [0.0001397373301966164], 'lstmA_size_1': [28.426018816294153], 'lstmA_size_2_2': [63.974663696402736], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [65.44108011351437], 'shared_lstm_size': [95.46357267839495], 'word2vec_size': [643.0]}
10, 0.986218, 1095.476566, {'batch_size': [4.396971387820571], 'dropout': [0.37620249914981185], 'learning_rate': [0.00018772927185789064], 'lstmA_size_1': [18.404267748330522], 'lstmA_size_2_2': [22.542945083181195], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [97.62680620250578], 'shared_lstm_size': [58.14080301839667], 'word2vec_size': [711.0]}
11, 0.981690, 153.563811, {'batch_size': [5.968848092572598], 'dropout': [0.09221010052954337], 'learning_rate': [0.0015588276203228784], 'lstmA_size_1': [33.477189757895765], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [26.830352525170753], 'shared_lstm_size': [77.06721274710958], 'word2vec_size': [567.0]}
12, 0.986698, 135.150091, {'batch_size': [5.5176953599327225], 'dropout': [0.033781303517543215], 'learning_rate': [0.0033179982624575196], 'lstmA_size_1': [18.61819579015176], 'lstmA_size_2_2': [135.85378586415518], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [97.0101691487642], 'shared_lstm_size': [11.779571551819762], 'word2vec_size': [518.0]}
13, 0.978952, 432.077932, {'batch_size': [4.827345511068675], 'dropout': [0.23936084987781492], 'learning_rate': [0.0006736466126854043], 'lstmA_size_1': [56.42902316725652], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [61.505654297863906], 'lstmA_size_3_3': [60.54505938320312], 'n_layers': [2], 'output_dim_embedding': [18.716722189742505], 'shared_lstm_size': [119.6014660089819], 'word2vec_size': [265.0]}
14, 0.971107, 379.297972, {'batch_size': [5.300295353276651], 'dropout': [0.32454385041320233], 'learning_rate': [0.00016732476057476834], 'lstmA_size_1': [61.57182189143306], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [60.51540277916956], 'shared_lstm_size': [44.29435147531588], 'word2vec_size': [340.0]}
15, 0.983533, 989.615012, {'batch_size': [3.878870577259123], 'dropout': [0.026333236720866793], 'learning_rate': [0.00032077091286631293], 'lstmA_size_1': [120.76345430206993], 'lstmA_size_2_2': [12.741248502275507], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [31.31949874805162], 'shared_lstm_size': [25.079577756374242], 'word2vec_size': [769.0]}
16, 0.984034, 1126.644134, {'batch_size': [3.540220642750142], 'dropout': [0.3187740286867653], 'learning_rate': [0.0005213550823713298], 'lstmA_size_1': [80.85247754621587], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [76.05181727874103], 'lstmA_size_3_3': [28.962738276670425], 'n_layers': [2], 'output_dim_embedding': [20.0818957973808], 'shared_lstm_size': [11.250147584962692], 'word2vec_size': [267.0]}
17, 1.155471, 3179.917217, {'batch_size': [5.195259691662065], 'dropout': [0.45607707248646523], 'learning_rate': [1.0800192424775495e-05], 'lstmA_size_1': [52.72568348517868], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [114.95659005593478], 'lstmA_size_3_3': [145.79237943858504], 'n_layers': [2], 'output_dim_embedding': [12.528294910320094], 'shared_lstm_size': [36.45478263986097], 'word2vec_size': [995.0]}
18, 0.987495, 578.382034, {'batch_size': [4.529227677349731], 'dropout': [0.38866726487311243], 'learning_rate': [0.00138392802992631], 'lstmA_size_1': [88.01634508813362], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [53.574668263433644], 'shared_lstm_size': [137.47391941258346], 'word2vec_size': [826.0]}
19, 0.981040, 246.715381, {'batch_size': [4.851695108350998], 'dropout': [0.038591357959562755], 'learning_rate': [0.0014754445670396579], 'lstmA_size_1': [49.480464394528234], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [10.230989125820166], 'shared_lstm_size': [10.351059254716828], 'word2vec_size': [703.0]}
Total time: 5:14:36.092455

Best parameters:{'batch_size': 5, 'dropout': 0.32454385041320233, 'learning_rate': 0.00016732476057476834, 'lstmA_size_1': 61, 'n_layers': {'n_layers': 1}, 'output_dim_embedding': 60, 'shared_lstm_size': 44, 'win_size': 4, 'word2vec_size': 340}

Next activity metrics:
              precision    recall  f1-score   support

           0      0.770     0.529     0.627       221
           1      0.643     0.596     0.619       483
           2      0.875     0.778     0.824         9
           3      0.852     0.968     0.906       155
           4      0.939     0.994     0.966       156
           5      0.738     0.770     0.754       139
           6      0.684     0.504     0.580       129
           7      0.707     0.369     0.485       157
           8      0.482     0.738     0.583       465
           9      0.247     0.190     0.215       116
          10      0.000     0.000     0.000         6
          11      0.000     0.000     0.000         5
          12      0.000     0.000     0.000         7
          13      0.455     0.405     0.429        37
          14      0.000     0.000     0.000        22
          15      0.000     0.000     0.000         1
          16      0.841     0.859     0.850       135

    accuracy                          0.643      2243
   macro avg      0.484     0.453     0.461      2243
weighted avg      0.647     0.643     0.632      2243


Next activity confusion matrix:
[[117  24   0   1   0   5   8   9  45  12   0   0   0   0   0   0   0]
 [  2 288   0   6   1   6   1   3 152  24   0   0   0   0   0   0   0]
 [  0   2   7   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0 150   1   0   0   0   2   0   0   0   0   0   0   0   0]
 [  0   0   0   0 155   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   1   0 107  21   3   6   0   0   0   0   0   0   0   0]
 [ 12   4   0   2   3   1  65   7  34   1   0   0   0   0   0   0   0]
 [  1  20   0   8   1  14   0  58  53   2   0   0   0   0   0   0   0]
 [  4  71   1   8   3  11   0   1 343  23   0   0   0   0   0   0   0]
 [  4  26   0   0   0   0   0   0  64  22   0   0   0   0   0   0   0]
 [  0   1   0   0   0   0   0   0   2   3   0   0   0   0   0   0   0]
 [  0   2   0   0   0   0   0   0   3   0   0   0   0   0   0   0   0]
 [  0   3   0   0   0   0   0   0   3   1   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0  15   0   0  22]
 [ 11   3   0   0   1   0   0   1   5   1   0   0   0   0   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0   0  18   0   0 116]]
