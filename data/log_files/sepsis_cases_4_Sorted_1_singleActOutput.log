
Hyperopt trials:
tid,loss,time,params used
0, 1.037194, 436.518990, {'batch_size': [4.455113329886135], 'dropout': [0.05987997262021011], 'learning_rate': [0.0004371202736591595], 'lstmA_size_1': [25.387485947351735], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [29.22950260015159], 'lstmA_size_3_3': [10.735887491606364], 'n_layers': [2], 'output_dim_embedding': [131.21853141620238], 'shared_lstm_size': [21.198052465539114], 'word2vec_size': [762.0]}
1, 1.053937, 1253.010945, {'batch_size': [3.394426936162322], 'dropout': [0.1926306791459706], 'learning_rate': [4.98711446028889e-05], 'lstmA_size_1': [60.756590603570196], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [21.358880565390496], 'shared_lstm_size': [47.858051027581055], 'word2vec_size': [267.0]}
2, 1.050837, 573.794508, {'batch_size': [3.3460237065596368], 'dropout': [0.12316425604502801], 'learning_rate': [0.0003679246537608464], 'lstmA_size_1': [73.28878065028184], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [141.22845405389924], 'lstmA_size_3_3': [31.695740218366517], 'n_layers': [2], 'output_dim_embedding': [103.08322049762474], 'shared_lstm_size': [24.700702937517104], 'word2vec_size': [298.0]}
3, 1.043038, 672.112953, {'batch_size': [5.54367223284321], 'dropout': [0.029315789226723454], 'learning_rate': [2.6403107484313748e-05], 'lstmA_size_1': [76.5072265923613], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [26.102679300748168], 'shared_lstm_size': [21.68341175881529], 'word2vec_size': [848.0]}
4, 1.051474, 1269.515182, {'batch_size': [3.4766226761317607], 'dropout': [0.12409432995958802], 'learning_rate': [3.3596892132032956e-05], 'lstmA_size_1': [19.253780601607026], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [81.31469265353522], 'shared_lstm_size': [58.657749182002014], 'word2vec_size': [455.0]}
5, 1.036463, 671.094695, {'batch_size': [5.2143478842875055], 'dropout': [0.44543486644124475], 'learning_rate': [0.0005941293604145415], 'lstmA_size_1': [13.158015490405493], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [88.45187095010427], 'lstmA_size_3_3': [41.87687877721392], 'n_layers': [2], 'output_dim_embedding': [27.97233447406047], 'shared_lstm_size': [49.26617322551477], 'word2vec_size': [677.0]}
6, 1.053704, 459.357256, {'batch_size': [5.692509414704551], 'dropout': [0.33619835216845867], 'learning_rate': [0.00016955979632513887], 'lstmA_size_1': [32.62730620175999], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [20.985991000685065], 'shared_lstm_size': [13.735859866189523], 'word2vec_size': [743.0]}
7, 1.045423, 330.528481, {'batch_size': [4.070015675131008], 'dropout': [0.12544907697031032], 'learning_rate': [0.003105091921719424], 'lstmA_size_1': [30.718367726184905], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [24.043526414658796], 'shared_lstm_size': [89.44727884425293], 'word2vec_size': [654.0]}
8, 1.063181, 1988.625712, {'batch_size': [4.909276069674776], 'dropout': [0.1489653436524218], 'learning_rate': [4.54503593844364e-05], 'lstmA_size_1': [48.22109209241669], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [57.47067410604048], 'lstmA_size_3_3': [15.909331648963239], 'n_layers': [2], 'output_dim_embedding': [10.588081099823901], 'shared_lstm_size': [10.806773982621236], 'word2vec_size': [448.0]}
9, 1.045448, 314.226781, {'batch_size': [4.805884428094148], 'dropout': [0.05853383044123267], 'learning_rate': [0.006575191521422384], 'lstmA_size_1': [40.08406393774793], 'lstmA_size_2_2': [26.280704211681375], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [14.18162190459069], 'shared_lstm_size': [18.424138206248987], 'word2vec_size': [771.0]}
10, 1.053982, 417.483454, {'batch_size': [4.29446727756307], 'dropout': [0.42778046972991673], 'learning_rate': [0.0031121539441213543], 'lstmA_size_1': [20.461052609363445], 'lstmA_size_2_2': [110.21001481277088], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [35.665360840668754], 'shared_lstm_size': [27.967561404534475], 'word2vec_size': [281.0]}
11, 1.114474, 3017.709908, {'batch_size': [4.630104662097587], 'dropout': [0.38864357636210484], 'learning_rate': [2.2201481412272473e-05], 'lstmA_size_1': [73.83535732901358], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [67.51149375672475], 'lstmA_size_3_3': [49.09264606655105], 'n_layers': [2], 'output_dim_embedding': [11.61832943140091], 'shared_lstm_size': [19.789336878308568], 'word2vec_size': [340.0]}
12, 1.050521, 582.843260, {'batch_size': [3.3278349961528675], 'dropout': [0.0928996567420543], 'learning_rate': [0.0005722139759249411], 'lstmA_size_1': [98.04566476948574], 'lstmA_size_2_2': [37.03364382629609], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [30.53424059686179], 'shared_lstm_size': [78.967020695616], 'word2vec_size': [38.0]}
13, 1.069332, 4758.506110, {'batch_size': [3.284376813984505], 'dropout': [0.2632639725944171], 'learning_rate': [2.0722680987974865e-05], 'lstmA_size_1': [35.7136989106885], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [83.9295475937326], 'lstmA_size_3_3': [28.05763906492993], 'n_layers': [2], 'output_dim_embedding': [41.296761912711794], 'shared_lstm_size': [27.852769054715043], 'word2vec_size': [415.0]}
14, 1.039665, 596.627755, {'batch_size': [4.188810725221083], 'dropout': [0.15843861604270265], 'learning_rate': [0.00021003165929760803], 'lstmA_size_1': [16.46726382134894], 'lstmA_size_2_2': [37.68583729392728], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [132.28117574607805], 'shared_lstm_size': [13.639418814206593], 'word2vec_size': [325.0]}
15, 1.051893, 1957.268065, {'batch_size': [3.686853131941583], 'dropout': [0.49624035727548393], 'learning_rate': [0.0003154990736283723], 'lstmA_size_1': [25.824216856183096], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [79.34264978932009], 'lstmA_size_3_3': [70.85672981069565], 'n_layers': [2], 'output_dim_embedding': [43.812429415214886], 'shared_lstm_size': [30.217648296906145], 'word2vec_size': [343.0]}
16, 1.053648, 302.215684, {'batch_size': [5.298293665831249], 'dropout': [0.11216833989855929], 'learning_rate': [0.0035204245762528365], 'lstmA_size_1': [84.68987694316746], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [10.709507275598838], 'lstmA_size_3_3': [42.48686964224557], 'n_layers': [2], 'output_dim_embedding': [56.831323171816095], 'shared_lstm_size': [21.655607908362267], 'word2vec_size': [384.0]}
17, 1.036704, 441.001313, {'batch_size': [5.196603602786733], 'dropout': [0.26349519192722787], 'learning_rate': [0.0045554787613740445], 'lstmA_size_1': [30.22143741743759], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [27.53802728565588], 'shared_lstm_size': [129.26748822165493], 'word2vec_size': [894.0]}
18, 1.032588, 377.102591, {'batch_size': [5.092848283354131], 'dropout': [0.39540236357295105], 'learning_rate': [0.0005565621894902805], 'lstmA_size_1': [71.52470023562826], 'lstmA_size_2_2': [61.00548519711745], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [14.315059699362704], 'shared_lstm_size': [25.489279024689996], 'word2vec_size': [966.0]}
19, 1.040087, 699.769773, {'batch_size': [4.9081831995644025], 'dropout': [0.13077502953964654], 'learning_rate': [0.0053112376171814], 'lstmA_size_1': [14.905370712105816], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [28.63109488028701], 'lstmA_size_3_3': [16.753083281384555], 'n_layers': [2], 'output_dim_embedding': [89.92353741056004], 'shared_lstm_size': [92.51526444093162], 'word2vec_size': [567.0]}
Total time: 5:51:59.313415

Best parameters:{'batch_size': 5, 'dropout': 0.39540236357295105, 'learning_rate': 0.0005565621894902805, 'lstmA_size_1': 71, 'n_layers': {'lstmA_size_2_2': 61, 'n_layers': 2}, 'output_dim_embedding': 14, 'shared_lstm_size': 25, 'win_size': 4, 'word2vec_size': 966}

Next activity metrics:
              precision    recall  f1-score   support

           0      0.000     0.000     0.000        23
           1      0.685     0.512     0.586       242
           2      0.629     0.575     0.601       605
           3      0.875     0.778     0.824         9
           4      0.857     0.968     0.909       155
           5      0.945     0.994     0.969       156
           6      0.712     0.748     0.730       139
           7      0.667     0.481     0.559       129
           8      0.589     0.396     0.474       250
           9      0.476     0.752     0.583       612
          10      0.000     0.000     0.000         8
          11      0.000     0.000     0.000         5
          12      0.000     0.000     0.000         9
          13      0.000     0.000     0.000         3
          14      0.045     0.008     0.013       133
          15      0.000     0.000     0.000         2
          16      0.889     1.000     0.941        24

    accuracy                          0.613      2504
   macro avg      0.434     0.424     0.423      2504
weighted avg      0.593     0.613     0.590      2504


Next activity confusion matrix:
[[  0  12   3   0   0   0   0   0   2   6   0   0   0   0   0   0   0]
 [  0 124  19   0   1   0   5   9  16  64   0   0   0   0   4   0   0]
 [  0  11 348   0   6   1   6   1  17 205   0   0   0   0  10   0   0]
 [  0   0   2   7   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0 150   1   0   0   0   4   0   0   0   0   0   0   0]
 [  0   0   0   0   0 155   1   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   0   1   0 104  21   4   8   0   0   0   0   0   0   0]
 [  0  13   3   0   2   3   5  62   3  38   0   0   0   0   0   0   0]
 [  0   2  43   0   7   1  14   0  99  84   0   0   0   0   0   0   0]
 [  0  10  90   1   8   3  11   0  23 460   0   0   0   0   6   0   0]
 [  0   0   0   0   0   0   0   0   0   8   0   0   0   0   0   0   0]
 [  0   0   2   0   0   0   0   0   0   3   0   0   0   0   0   0   0]
 [  0   0   4   0   0   0   0   0   0   4   0   0   0   0   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3]
 [  0   8  39   0   0   0   0   0   4  81   0   0   0   0   1   0   0]
 [  0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  24]]
