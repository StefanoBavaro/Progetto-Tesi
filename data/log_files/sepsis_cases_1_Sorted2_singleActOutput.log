
Hyperopt trials:
tid,loss,params used
0, 1.055904, {'batch_size': [3.5173323116853483], 'dropout': [0.3001340788846321], 'learning_rate': [5.02753860981615e-05], 'lstmA_size_1': [14.686812234282868], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [33.053364224634485], 'lstmA_size_3_3': [31.892525930599763], 'n_layers': [2], 'output_dim_embedding': [62.35266839211508]}
1, 1.092549, {'batch_size': [5.8596626999558055], 'dropout': [0.1578935763295744], 'learning_rate': [1.9732822298579302e-05], 'lstmA_size_1': [16.135896287451658], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [37.83533215025318]}
2, 1.015913, {'batch_size': [5.568156904908966], 'dropout': [0.23808137858112094], 'learning_rate': [0.0002435207666132766], 'lstmA_size_1': [14.006713020311503], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [140.06208074473483]}
3, 1.013499, {'batch_size': [5.268590759777467], 'dropout': [0.4527911095064964], 'learning_rate': [0.0005032962703866873], 'lstmA_size_1': [37.582923124981775], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [70.37525294570568], 'lstmA_size_3_3': [14.277710978581473], 'n_layers': [2], 'output_dim_embedding': [35.04593689618284]}
4, 1.072737, {'batch_size': [3.5477446933103063], 'dropout': [0.07092917251833591], 'learning_rate': [0.00605573795242561], 'lstmA_size_1': [14.081521642501542], 'lstmA_size_2_2': [108.00466520841759], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [19.490534656896624]}
5, 1.020694, {'batch_size': [5.360174858158234], 'dropout': [0.31738314522340594], 'learning_rate': [0.00027019548349636684], 'lstmA_size_1': [44.40991620717749], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [25.750261531731457]}
6, 1.029184, {'batch_size': [5.104330123855549], 'dropout': [0.38051141563524343], 'learning_rate': [0.0003538953928795215], 'lstmA_size_1': [20.98641198952636], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [16.274091463658575], 'lstmA_size_3_3': [23.23249401111194], 'n_layers': [2], 'output_dim_embedding': [29.79873139117338]}
7, 1.042868, {'batch_size': [3.772744167949283], 'dropout': [0.36793114501531626], 'learning_rate': [1.6217258138551293e-05], 'lstmA_size_1': [33.25818112289281], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [98.57132247020591], 'lstmA_size_3_3': [44.370487198298314], 'n_layers': [2], 'output_dim_embedding': [49.34335310058666]}
8, 1.012375, {'batch_size': [4.233577814932806], 'dropout': [0.3561129185520458], 'learning_rate': [0.0012150466335821295], 'lstmA_size_1': [121.90001125494513], 'lstmA_size_2_2': [135.65426154061967], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [22.08955914101202]}
9, 1.026897, {'batch_size': [3.255248306159385], 'dropout': [0.47503477620675294], 'learning_rate': [0.00621226497561796], 'lstmA_size_1': [25.63401465309489], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [45.06918293029988]}
10, 1.082760, {'batch_size': [3.3146431450440885], 'dropout': [0.34977811008633836], 'learning_rate': [2.296673615019181e-05], 'lstmA_size_1': [27.791199426905333], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [44.05772377748364], 'lstmA_size_3_3': [21.155460993274282], 'n_layers': [2], 'output_dim_embedding': [21.446691337861143]}
11, 1.151184, {'batch_size': [3.62185903700054], 'dropout': [0.04275570133020812], 'learning_rate': [1.635359058422938e-05], 'lstmA_size_1': [23.881996342991783], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [10.805217179712125]}
12, 1.014058, {'batch_size': [5.763996929735596], 'dropout': [0.2610510561239313], 'learning_rate': [0.0007078496598802603], 'lstmA_size_1': [19.05173127565719], 'lstmA_size_2_2': [24.654311228901697], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [84.60918848740506]}
13, 1.009639, {'batch_size': [5.064473795893245], 'dropout': [0.10231185638620666], 'learning_rate': [0.00038743346353173444], 'lstmA_size_1': [12.170622455911186], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [10.631172452170711], 'lstmA_size_3_3': [53.87745981916525], 'n_layers': [2], 'output_dim_embedding': [17.815571656241914]}
14, 1.080217, {'batch_size': [4.757426558729851], 'dropout': [0.4522059255508234], 'learning_rate': [0.0012492753872657594], 'lstmA_size_1': [11.686848826492323], 'lstmA_size_2_2': [10.950212994037278], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [12.36331783987981]}
15, 1.031840, {'batch_size': [4.446531221441175], 'dropout': [0.13420835843523865], 'learning_rate': [0.007487701685655623], 'lstmA_size_1': [110.1277785097878], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [132.64028712038606]}
16, 1.011107, {'batch_size': [3.466079998427649], 'dropout': [0.3016738962684958], 'learning_rate': [0.0010975378130976706], 'lstmA_size_1': [43.55595849960584], 'lstmA_size_2_2': [38.94623374228514], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [28.144051310566958]}
17, 1.009113, {'batch_size': [5.951062542019821], 'dropout': [0.2013079169964877], 'learning_rate': [0.00041428140609520007], 'lstmA_size_1': [34.223305538523334], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [33.44871806968378], 'lstmA_size_3_3': [78.30167178052575], 'n_layers': [2], 'output_dim_embedding': [51.22345476573362]}
18, 1.024795, {'batch_size': [3.791232660317874], 'dropout': [0.2890175530916804], 'learning_rate': [0.0004070041508092573], 'lstmA_size_1': [31.07201636032692], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [73.69578417253132]}
19, 1.162030, {'batch_size': [4.162741137230013], 'dropout': [0.45363073370617657], 'learning_rate': [1.289882340687344e-05], 'lstmA_size_1': [38.283065712752474], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [23.346230538459448]}

Best parameters:{'batch_size': 5, 'dropout': 0.2013079169964877, 'learning_rate': 0.00041428140609520007, 'lstmA_size_1': 34, 'n_layers': {'lstmA_size_2_3': 33, 'lstmA_size_3_3': 78, 'n_layers': 3}, 'output_dim_embedding': 51, 'win_size': 4}

Next activity metrics:
              precision    recall  f1-score   support

           0      0.000     0.000     0.000        18
           1      0.885     1.000     0.939       139
           2      0.875     0.778     0.824         9
           3      0.945     1.000     0.972       156
           4      0.857     0.968     0.909       155
           5      0.556     0.420     0.478       250
           6      0.487     0.698     0.574       612
           7      0.590     0.590     0.590       605
           8      0.670     0.488     0.565       129
           9      0.731     0.763     0.746       139
          10      0.728     0.508     0.599       242
          11      0.137     0.053     0.076       133
          12      0.000     0.000     0.000        23
          13      0.000     0.000     0.000         8
          14      0.000     0.000     0.000         5
          15      0.000     0.000     0.000         9
          16      0.000     0.000     0.000         2

    accuracy                          0.623      2634
   macro avg      0.439     0.427     0.428      2634
weighted avg      0.603     0.623     0.604      2634


Next activity confusion matrix:
[[  0  18   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0 139   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   7   0   0   0   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0 156   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   1 150   0   3   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   1   7 105  73  48   0  14   1   1   0   0   0   0   0]
 [  0   0   1   3   8  30 427 109   0  11   9  14   0   0   0   0   0]
 [  0   0   0   1   6  19 191 357   2   5  10  14   0   0   0   0   0]
 [  0   0   0   3   2   6  34   3  63   4  12   2   0   0   0   0   0]
 [  0   0   0   0   1   3   7   1  21 106   0   0   0   0   0   0   0]
 [  0   0   0   0   1  19  46  28   8   5 123  12   0   0   0   0   0]
 [  0   0   0   0   0   4  76  43   0   0   3   7   0   0   0   0   0]
 [  0   0   0   0   0   2   4   5   0   0  11   1   0   0   0   0   0]
 [  0   0   0   0   0   0   8   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   2   3   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   5   4   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0]]
