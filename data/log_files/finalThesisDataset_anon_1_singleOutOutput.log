
Hyperopt trials:
tid,loss,time,params used
0, 0.291512, 115.967835, {'batch_size': [5.929447381405473], 'dropout': [0.4858916104790946], 'learning_rate': [3.972812044126213e-05], 'lstmO_size_1': [28.864113141976517], 'lstmO_size_2_2': [], 'lstmO_size_2_3': [24.972053907710585], 'lstmO_size_3_3': [96.00915403231193], 'n_layers': [2], 'output_dim_embedding': [42.40937813859936], 'shared_lstm_size': [12.208315373972901], 'word2vec_size': [116.0]}
1, 0.261235, 176.542367, {'batch_size': [3.965597405442536], 'dropout': [0.13894245923180526], 'learning_rate': [0.0002781363016273792], 'lstmO_size_1': [78.45168979775902], 'lstmO_size_2_2': [], 'lstmO_size_2_3': [41.52575257493522], 'lstmO_size_3_3': [126.41829145747778], 'n_layers': [2], 'output_dim_embedding': [81.25148776712412], 'shared_lstm_size': [122.75560971160223], 'word2vec_size': [83.0]}
2, 0.268751, 105.473045, {'batch_size': [4.861076025402999], 'dropout': [0.2265925946672913], 'learning_rate': [0.0002040431058726026], 'lstmO_size_1': [14.954572684632202], 'lstmO_size_2_2': [], 'lstmO_size_2_3': [40.16086184074009], 'lstmO_size_3_3': [87.76866213532307], 'n_layers': [2], 'output_dim_embedding': [72.82015014043556], 'shared_lstm_size': [28.9927808147652], 'word2vec_size': [692.0]}
3, 0.277242, 237.788618, {'batch_size': [3.956531907017541], 'dropout': [0.3456708115584958], 'learning_rate': [0.00038107770496915625], 'lstmO_size_1': [53.97339706551248], 'lstmO_size_2_2': [], 'lstmO_size_2_3': [15.331602759968844], 'lstmO_size_3_3': [142.38720620465006], 'n_layers': [2], 'output_dim_embedding': [46.15028730496604], 'shared_lstm_size': [48.09459240454464], 'word2vec_size': [318.0]}
4, 0.376008, 294.521805, {'batch_size': [4.572810739733666], 'dropout': [0.48949573140608144], 'learning_rate': [1.0678518070165448e-05], 'lstmO_size_1': [30.196941747034604], 'lstmO_size_2_2': [], 'lstmO_size_2_3': [24.845450994069548], 'lstmO_size_3_3': [15.649441069290509], 'n_layers': [2], 'output_dim_embedding': [14.00271486139758], 'shared_lstm_size': [18.652487040018624], 'word2vec_size': [356.0]}
5, 0.243301, 51.182312, {'batch_size': [4.462670536572147], 'dropout': [0.4583196559068799], 'learning_rate': [0.0009095947357636424], 'lstmO_size_1': [23.3063637641717], 'lstmO_size_2_2': [68.20295368919453], 'lstmO_size_2_3': [], 'lstmO_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [21.031145019907655], 'shared_lstm_size': [18.372736088537724], 'word2vec_size': [770.0]}
6, 0.207635, 40.724832, {'batch_size': [5.961521472380035], 'dropout': [0.3044803043009344], 'learning_rate': [0.0034355561917321993], 'lstmO_size_1': [11.105478208512292], 'lstmO_size_2_2': [], 'lstmO_size_2_3': [], 'lstmO_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [14.013895873383987], 'shared_lstm_size': [42.753608802073636], 'word2vec_size': [885.0]}
7, 0.259899, 99.665135, {'batch_size': [3.021996693401991], 'dropout': [0.14849036644445102], 'learning_rate': [0.0010968246586699414], 'lstmO_size_1': [39.12485969534616], 'lstmO_size_2_2': [], 'lstmO_size_2_3': [], 'lstmO_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [12.404794764131918], 'shared_lstm_size': [11.413062331382843], 'word2vec_size': [907.0]}
8, 0.297251, 146.438386, {'batch_size': [4.234321846408459], 'dropout': [0.371573882329473], 'learning_rate': [2.571827895524046e-05], 'lstmO_size_1': [22.50035296885125], 'lstmO_size_2_2': [74.04455168531237], 'lstmO_size_2_3': [], 'lstmO_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [58.36851001291171], 'shared_lstm_size': [83.86820143130642], 'word2vec_size': [387.0]}
9, 0.471360, 92.161642, {'batch_size': [3.134296853079758], 'dropout': [0.34484445077277603], 'learning_rate': [1.3523194081617989e-05], 'lstmO_size_1': [146.08670001886998], 'lstmO_size_2_2': [23.858757835145294], 'lstmO_size_2_3': [], 'lstmO_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [74.7804240322008], 'shared_lstm_size': [10.099834857353734], 'word2vec_size': [84.0]}
10, 0.315436, 299.333594, {'batch_size': [3.362181571036362], 'dropout': [0.37374384020006113], 'learning_rate': [2.2129162412403887e-05], 'lstmO_size_1': [72.94379423799268], 'lstmO_size_2_2': [], 'lstmO_size_2_3': [20.67184068409079], 'lstmO_size_3_3': [29.984926250975338], 'n_layers': [2], 'output_dim_embedding': [13.750701771759392], 'shared_lstm_size': [18.96338657809117], 'word2vec_size': [426.0]}
11, 0.267649, 138.677150, {'batch_size': [4.2537731388077], 'dropout': [0.11834763072636728], 'learning_rate': [0.00019446313951319602], 'lstmO_size_1': [146.0892519405063], 'lstmO_size_2_2': [], 'lstmO_size_2_3': [11.678166089157754], 'lstmO_size_3_3': [99.01073963468733], 'n_layers': [2], 'output_dim_embedding': [53.89762243689732], 'shared_lstm_size': [27.49552120961107], 'word2vec_size': [732.0]}
12, 0.287273, 383.975941, {'batch_size': [3.204636358959499], 'dropout': [0.43405096511107366], 'learning_rate': [0.00035721705459907765], 'lstmO_size_1': [29.875408626705212], 'lstmO_size_2_2': [20.558874598914777], 'lstmO_size_2_3': [], 'lstmO_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [12.492618886887035], 'shared_lstm_size': [141.54118600668087], 'word2vec_size': [1016.0]}
13, 0.263063, 86.243629, {'batch_size': [5.46561786650352], 'dropout': [0.048001540721616165], 'learning_rate': [0.00010484311199756683], 'lstmO_size_1': [30.383671026098266], 'lstmO_size_2_2': [], 'lstmO_size_2_3': [70.33970176641783], 'lstmO_size_3_3': [56.749899748665094], 'n_layers': [2], 'output_dim_embedding': [33.104064037596885], 'shared_lstm_size': [15.711694710843187], 'word2vec_size': [518.0]}
14, 0.279781, 458.967437, {'batch_size': [3.3138040063333634], 'dropout': [0.3732812729001596], 'learning_rate': [0.00016958922735139], 'lstmO_size_1': [86.33006201577456], 'lstmO_size_2_2': [], 'lstmO_size_2_3': [62.91926312052618], 'lstmO_size_3_3': [71.70782717805892], 'n_layers': [2], 'output_dim_embedding': [20.64039016895433], 'shared_lstm_size': [118.1601101650919], 'word2vec_size': [645.0]}
15, 0.286040, 74.668414, {'batch_size': [4.416901673324534], 'dropout': [0.47034760902309314], 'learning_rate': [0.0001763680580371409], 'lstmO_size_1': [28.696903263489965], 'lstmO_size_2_2': [], 'lstmO_size_2_3': [21.754997568052772], 'lstmO_size_3_3': [130.25451212179118], 'n_layers': [2], 'output_dim_embedding': [13.360844602365113], 'shared_lstm_size': [31.128442002528985], 'word2vec_size': [48.0]}
16, 0.212982, 218.133678, {'batch_size': [3.3108385831980685], 'dropout': [0.39894597953321187], 'learning_rate': [0.0017201264486706293], 'lstmO_size_1': [78.08513147204735], 'lstmO_size_2_2': [], 'lstmO_size_2_3': [], 'lstmO_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [91.70313710902997], 'shared_lstm_size': [97.28792271448302], 'word2vec_size': [366.0]}
17, 0.247487, 44.377539, {'batch_size': [5.258070581351067], 'dropout': [0.3429692379156424], 'learning_rate': [0.0034579395474801235], 'lstmO_size_1': [31.226837219934197], 'lstmO_size_2_2': [28.291571069778236], 'lstmO_size_2_3': [], 'lstmO_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [43.414919209016425], 'shared_lstm_size': [19.514118430389193], 'word2vec_size': [480.0]}
18, 0.292796, 192.269643, {'batch_size': [3.8766602302481625], 'dropout': [0.3694960549364127], 'learning_rate': [4.451864707084317e-05], 'lstmO_size_1': [46.166128370259244], 'lstmO_size_2_2': [], 'lstmO_size_2_3': [], 'lstmO_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [30.410915285549276], 'shared_lstm_size': [57.04875571498458], 'word2vec_size': [472.0]}
19, 0.210684, 35.809422, {'batch_size': [5.939166839809479], 'dropout': [0.20874752819220577], 'learning_rate': [0.0052410635770663745], 'lstmO_size_1': [11.373106360690713], 'lstmO_size_2_2': [], 'lstmO_size_2_3': [], 'lstmO_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [95.98001807018635], 'shared_lstm_size': [18.919197203827153], 'word2vec_size': [551.0]}
Total time: 0:54:52.922424

Best parameters:{'batch_size': 5, 'dropout': 0.3044803043009344, 'learning_rate': 0.0034355561917321993, 'lstmO_size_1': 11, 'n_layers': {'n_layers': 1}, 'output_dim_embedding': 14, 'shared_lstm_size': 42, 'win_size': 4, 'word2vec_size': 885}

Outcome metrics:
              precision    recall  f1-score   support

           0      0.838     0.849     0.844       550
           1      0.153     0.143     0.148       105

    accuracy                          0.736       655
   macro avg      0.496     0.496     0.496       655
weighted avg      0.729     0.736     0.732       655


Outcome confusion matrix:
[[467  83]
 [ 90  15]]
