
Hyperopt trials:
tid,loss,time,params used
0, 1.770354, 113.877698, {'batch_size': [5.484951249991009], 'dropout': [0.33386063132552013], 'learning_rate': [0.00034800597102177435], 'lstmA_size_1': [88.54054455835775], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [24.32366740389363], 'lstmA_size_3_3': [11.629271342961426], 'n_layers': [2], 'output_dim_embedding': [31.83199639210202], 'shared_lstm_size': [30.641885629579914], 'word2vec_size': [252.0]}
1, 1.713746, 46.592406, {'batch_size': [5.9131755768783325], 'dropout': [0.31046479415052164], 'learning_rate': [0.00042566964855626397], 'lstmA_size_1': [17.30265454881059], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [22.071432494538676], 'shared_lstm_size': [69.30596640300972], 'word2vec_size': [921.0]}
2, 1.724432, 177.736517, {'batch_size': [3.0427225878053745], 'dropout': [0.4242927222865775], 'learning_rate': [0.00041939833431922446], 'lstmA_size_1': [89.17414742495443], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [18.112081227777086], 'lstmA_size_3_3': [58.586241039911414], 'n_layers': [2], 'output_dim_embedding': [14.622062480770909], 'shared_lstm_size': [20.344214202517062], 'word2vec_size': [365.0]}
3, 1.746933, 51.455120, {'batch_size': [3.623439666812458], 'dropout': [0.29846498883041217], 'learning_rate': [0.0012941372672066313], 'lstmA_size_1': [19.05158566567024], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [15.024156862165523], 'shared_lstm_size': [29.910677955869332], 'word2vec_size': [906.0]}
4, 1.755599, 136.570541, {'batch_size': [5.868942547322545], 'dropout': [0.061557404680955774], 'learning_rate': [0.00021649491708544558], 'lstmA_size_1': [83.62329952821804], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [19.737190624286615], 'lstmA_size_3_3': [39.653788589780156], 'n_layers': [2], 'output_dim_embedding': [54.153290716147545], 'shared_lstm_size': [137.34968139593215], 'word2vec_size': [895.0]}
5, 1.698682, 66.978782, {'batch_size': [4.419552359639053], 'dropout': [0.1660410896258958], 'learning_rate': [0.0004433368329386584], 'lstmA_size_1': [120.8039193224386], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [12.035127978973115], 'shared_lstm_size': [10.930219744389625], 'word2vec_size': [934.0]}
6, 1.794244, 50.400187, {'batch_size': [4.629713435185459], 'dropout': [0.00685708258322415], 'learning_rate': [0.008201326107328166], 'lstmA_size_1': [13.109642678891303], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [79.08123128126746], 'lstmA_size_3_3': [15.704503002298912], 'n_layers': [2], 'output_dim_embedding': [28.034471622815243], 'shared_lstm_size': [19.664919704936697], 'word2vec_size': [60.0]}
7, 1.746223, 114.234154, {'batch_size': [3.2238049689424377], 'dropout': [0.42973863002456214], 'learning_rate': [0.00026976606404829884], 'lstmA_size_1': [37.71239740602305], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [12.247778179271254], 'shared_lstm_size': [126.9346538084508], 'word2vec_size': [132.0]}
8, 1.731458, 24.749690, {'batch_size': [5.577613333950623], 'dropout': [0.2365753761807538], 'learning_rate': [0.00769752377654489], 'lstmA_size_1': [28.599180153923946], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [41.470436583297726], 'shared_lstm_size': [40.20632018274751], 'word2vec_size': [752.0]}
9, 1.734377, 82.595583, {'batch_size': [4.76441918548821], 'dropout': [0.24570073235869988], 'learning_rate': [0.0030001619935319285], 'lstmA_size_1': [20.779209521009818], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [10.8374402255066], 'lstmA_size_3_3': [134.04185123363712], 'n_layers': [2], 'output_dim_embedding': [30.85102586190747], 'shared_lstm_size': [102.45636723720715], 'word2vec_size': [569.0]}
10, 1.809725, 368.593462, {'batch_size': [5.221985923992127], 'dropout': [0.4789441144171175], 'learning_rate': [2.578492804717373e-05], 'lstmA_size_1': [135.4912889086799], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [37.886496712080046], 'shared_lstm_size': [50.509676528374634], 'word2vec_size': [971.0]}
11, 1.783106, 323.541945, {'batch_size': [5.4772027322930015], 'dropout': [0.03885564812946457], 'learning_rate': [3.6707195890608814e-05], 'lstmA_size_1': [73.95197595576431], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [65.35953814587731], 'lstmA_size_3_3': [54.12701254503388], 'n_layers': [2], 'output_dim_embedding': [58.86387511063267], 'shared_lstm_size': [11.03996646390689], 'word2vec_size': [684.0]}
12, 1.770671, 149.693199, {'batch_size': [4.813389599583617], 'dropout': [0.327697442085204], 'learning_rate': [0.00046215802071218913], 'lstmA_size_1': [119.00452991456798], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [57.39299315445117], 'lstmA_size_3_3': [41.20708492505006], 'n_layers': [2], 'output_dim_embedding': [14.7122060445384], 'shared_lstm_size': [100.60595833840922], 'word2vec_size': [312.0]}
13, 1.793145, 237.635859, {'batch_size': [5.667624459182393], 'dropout': [0.4023203024423015], 'learning_rate': [3.146914462014056e-05], 'lstmA_size_1': [82.90819863888015], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [42.78209699894046], 'shared_lstm_size': [83.47918482427187], 'word2vec_size': [884.0]}
14, 1.745093, 153.839125, {'batch_size': [3.0257620858784637], 'dropout': [0.11583267679259163], 'learning_rate': [0.0011271031636098257], 'lstmA_size_1': [41.28914169906731], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [118.87998630301222], 'lstmA_size_3_3': [23.784438370789694], 'n_layers': [2], 'output_dim_embedding': [38.76049146354187], 'shared_lstm_size': [106.87267640473294], 'word2vec_size': [503.0]}
15, 1.744431, 167.396250, {'batch_size': [3.051309127191825], 'dropout': [0.03871410941914799], 'learning_rate': [0.0002839119160437426], 'lstmA_size_1': [12.705504706326703], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [134.89599024133818], 'lstmA_size_3_3': [26.629370186968934], 'n_layers': [2], 'output_dim_embedding': [116.8609271543843], 'shared_lstm_size': [117.05214971185832], 'word2vec_size': [398.0]}
16, 1.736211, 42.450189, {'batch_size': [3.035878009131923], 'dropout': [0.04596239539894348], 'learning_rate': [0.0016726195257447723], 'lstmA_size_1': [25.09421442596013], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [92.05060569696379], 'shared_lstm_size': [15.238786950129544], 'word2vec_size': [243.0]}
17, 1.720272, 25.842723, {'batch_size': [5.413605246749871], 'dropout': [0.33731384800677155], 'learning_rate': [0.005905918355422863], 'lstmA_size_1': [91.93968378410952], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [20.977607094246174], 'shared_lstm_size': [24.9834176390681], 'word2vec_size': [506.0]}
18, 1.772928, 363.567580, {'batch_size': [5.891868630282261], 'dropout': [0.14702704276646017], 'learning_rate': [3.6330857985980575e-05], 'lstmA_size_1': [18.873083371608235], 'lstmA_size_2_2': [25.719320690045805], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [92.74924056943833], 'shared_lstm_size': [80.081147284743], 'word2vec_size': [988.0]}
19, 1.754191, 56.746946, {'batch_size': [3.617824142562905], 'dropout': [0.16674067468781884], 'learning_rate': [0.0034127183717790337], 'lstmA_size_1': [19.04352868540483], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [83.28208662434082], 'shared_lstm_size': [34.256323053935525], 'word2vec_size': [960.0]}
Total time: 0:45:54.497957

Best parameters:{'batch_size': 4, 'dropout': 0.1660410896258958, 'learning_rate': 0.0004433368329386584, 'lstmA_size_1': 120, 'n_layers': {'n_layers': 1}, 'output_dim_embedding': 12, 'shared_lstm_size': 10, 'win_size': 4, 'word2vec_size': 934}

Next activity metrics:
              precision    recall  f1-score   support

           0      0.500     0.357     0.417        14
           1      0.000     0.000     0.000         5
           3      0.190     0.286     0.229        14
           4      0.176     0.176     0.176        17
           7      0.556     0.500     0.526        10
           8      0.333     0.500     0.400         2
           9      0.000     0.000     0.000         0
          10      0.000     0.000     0.000         0
          11      0.000     0.000     0.000         0
          14      0.200     0.333     0.250         3
          16      0.786     1.000     0.880        11
          17      0.653     0.889     0.753        36
          18      0.696     0.914     0.790        35
          19      0.625     0.968     0.759        31
          20      0.682     0.938     0.789        16
          21      0.667     1.000     0.800         4
          22      0.000     0.000     0.000        31
          23      0.000     0.000     0.000         5
          25      0.000     0.000     0.000        14
          26      0.500     0.625     0.556         8
          27      0.727     0.267     0.390        30

    accuracy                          0.545       286
   macro avg      0.347     0.417     0.367       286
weighted avg      0.471     0.545     0.485       286


Next activity confusion matrix:
[[ 5  1  2  0  3  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  2]
 [ 1  0  3  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0]
 [ 0  3  4  4  0  1  0  0  0  1  0  0  1  0  0  0  0  0  0  0  0]
 [ 1  0  4  3  0  1  0  2  0  0  0  1  3  1  1  0  0  0  0  0  0]
 [ 2  0  1  0  5  0  0  0  0  0  1  0  0  0  0  0  0  0  0  1  0]
 [ 0  0  0  0  0  1  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  1  0  0  0  0  1  0  0  1  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  1  0  0  0  0  0  0  0  0 32  0  0  0  0  2  0  1  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  1 32  0  0  0  0  0  0  2  0]
 [ 0  0  1  0  0  0  0  0  0  0  0  0  0 30  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 15  0  0  0  0  1  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0]
 [ 0  0  1  6  0  0  0  0  0  0  0  3  7 10  3  1  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  1  1  0]
 [ 0  0  0  1  0  0  0  0  0  0  0  5  2  4  1  0  0  0  0  0  1]
 [ 0  0  0  0  0  0  0  0  0  0  0  2  0  1  0  0  0  0  0  5  0]
 [ 1  0  4  3  1  0  0  0  0  0  2  5  1  2  1  1  1  0  0  0  8]]
