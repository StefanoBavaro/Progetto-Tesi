
Hyperopt trials:
tid,loss,time,params used
0, 1.033978, 977.247318, {'batch_size': [4.383028370402289], 'dropout': [0.42993083830187084], 'learning_rate': [4.958567973678969e-05], 'lstmA_size_1': [15.762715927844411], 'lstmA_size_2_2': [105.06899525298083], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [105.80297649692793], 'shared_lstm_size': [123.68123817671362], 'word2vec_size': [964.0]}
1, 1.022289, 170.938063, {'batch_size': [4.88417480992088], 'dropout': [0.27888572881204815], 'learning_rate': [0.0018928771094733545], 'lstmA_size_1': [91.96914367460306], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [86.25991840320046], 'shared_lstm_size': [16.833576514034313], 'word2vec_size': [163.0]}
2, 1.016170, 407.206358, {'batch_size': [4.689973288822307], 'dropout': [0.16746494772547155], 'learning_rate': [0.00030209078296208354], 'lstmA_size_1': [134.8799554334861], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [137.01003644291086], 'lstmA_size_3_3': [37.17896153840966], 'n_layers': [2], 'output_dim_embedding': [143.1015352684186], 'shared_lstm_size': [30.648844138784806], 'word2vec_size': [530.0]}
3, 1.031501, 368.603130, {'batch_size': [3.796906403822419], 'dropout': [0.39142767590151195], 'learning_rate': [0.000898953653542086], 'lstmA_size_1': [55.404236962521544], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [127.81362350778754], 'shared_lstm_size': [65.97579734889703], 'word2vec_size': [282.0]}
4, 1.055190, 3290.755522, {'batch_size': [3.8449326375715893], 'dropout': [0.39591056416878917], 'learning_rate': [8.903760666476388e-05], 'lstmA_size_1': [62.347351260410676], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [48.78529465169795], 'lstmA_size_3_3': [24.35876677094767], 'n_layers': [2], 'output_dim_embedding': [12.264471483638674], 'shared_lstm_size': [13.867503605192072], 'word2vec_size': [202.0]}
5, 1.035413, 545.666137, {'batch_size': [4.427996266382659], 'dropout': [0.24438292211901325], 'learning_rate': [0.007979666185252891], 'lstmA_size_1': [26.102466474634795], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [10.906744123443154], 'lstmA_size_3_3': [96.96442270683121], 'n_layers': [2], 'output_dim_embedding': [36.4015509591858], 'shared_lstm_size': [43.53719771602684], 'word2vec_size': [164.0]}
6, 1.159966, 1630.723771, {'batch_size': [4.49337944972247], 'dropout': [0.22463629783790018], 'learning_rate': [2.221124860629229e-05], 'lstmA_size_1': [17.12646451830706], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [19.519606258360735], 'lstmA_size_3_3': [38.59728791979755], 'n_layers': [2], 'output_dim_embedding': [126.2873754965441], 'shared_lstm_size': [17.607152672095403], 'word2vec_size': [207.0]}
7, 1.041721, 783.788868, {'batch_size': [4.793503575667098], 'dropout': [0.24576715579051972], 'learning_rate': [0.007550948170517124], 'lstmA_size_1': [96.50775062398034], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [14.758553576201102], 'lstmA_size_3_3': [14.341312120975148], 'n_layers': [2], 'output_dim_embedding': [91.67092071313606], 'shared_lstm_size': [24.85902042226252], 'word2vec_size': [488.0]}
8, 1.006389, 378.693105, {'batch_size': [5.868089440732254], 'dropout': [0.18087317860759738], 'learning_rate': [0.00020808266399103585], 'lstmA_size_1': [114.46316251339336], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [79.4845234062157], 'lstmA_size_3_3': [27.162255697850746], 'n_layers': [2], 'output_dim_embedding': [33.23509842237123], 'shared_lstm_size': [42.11599827729345], 'word2vec_size': [766.0]}
9, 1.139159, 2645.831704, {'batch_size': [3.924252952322478], 'dropout': [0.487390500906361], 'learning_rate': [0.00016842769731779906], 'lstmA_size_1': [30.93354845788706], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [33.58512851225137], 'lstmA_size_3_3': [12.107594999641774], 'n_layers': [2], 'output_dim_embedding': [46.17086777134342], 'shared_lstm_size': [41.36578806672204], 'word2vec_size': [689.0]}
10, 1.006832, 371.149774, {'batch_size': [4.530513578932198], 'dropout': [0.4757532408376548], 'learning_rate': [0.00038775091697510394], 'lstmA_size_1': [112.07981276576608], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [35.191512077741024], 'shared_lstm_size': [51.45720849109234], 'word2vec_size': [425.0]}
11, 0.994138, 1311.176050, {'batch_size': [4.51500035937418], 'dropout': [0.33016206958553795], 'learning_rate': [0.00018388129870345848], 'lstmA_size_1': [80.3812059279248], 'lstmA_size_2_2': [23.136731993373335], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [14.527778817953621], 'shared_lstm_size': [37.95661026315703], 'word2vec_size': [852.0]}
12, 1.022015, 1201.187893, {'batch_size': [3.8085167634439516], 'dropout': [0.41374773131544984], 'learning_rate': [0.00016575355793489326], 'lstmA_size_1': [52.84501188612466], 'lstmA_size_2_2': [69.19650058645512], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [135.592173810037], 'shared_lstm_size': [35.6242766539749], 'word2vec_size': [874.0]}
13, 1.013008, 531.594962, {'batch_size': [4.079776243854726], 'dropout': [0.3075316561402948], 'learning_rate': [0.0011657760691902324], 'lstmA_size_1': [55.65271828269868], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [25.28018803732911], 'lstmA_size_3_3': [69.99114911274837], 'n_layers': [2], 'output_dim_embedding': [58.326415937000206], 'shared_lstm_size': [12.137174501826589], 'word2vec_size': [913.0]}
14, 1.017461, 644.701587, {'batch_size': [3.75851229148701], 'dropout': [0.029289217682891555], 'learning_rate': [0.0014631978661154882], 'lstmA_size_1': [99.40139332869634], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [40.279577264805965], 'lstmA_size_3_3': [43.05702018836521], 'n_layers': [2], 'output_dim_embedding': [18.723512609057895], 'shared_lstm_size': [76.71310783564985], 'word2vec_size': [829.0]}
15, 1.011124, 517.140208, {'batch_size': [5.125624549596562], 'dropout': [0.30151262055477634], 'learning_rate': [0.00014289054567087517], 'lstmA_size_1': [22.247200336172533], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [0], 'output_dim_embedding': [113.88895690208511], 'shared_lstm_size': [119.51397809869052], 'word2vec_size': [509.0]}
16, 1.053719, 1899.914634, {'batch_size': [3.4112887134828194], 'dropout': [0.0031310388355839103], 'learning_rate': [1.1646006620742166e-05], 'lstmA_size_1': [72.38399375975965], 'lstmA_size_2_2': [54.46047558698348], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [12.81996628770708], 'shared_lstm_size': [18.254705678361915], 'word2vec_size': [962.0]}
17, 1.006721, 374.471219, {'batch_size': [5.837331696968269], 'dropout': [0.15168636564838966], 'learning_rate': [0.00028927117596226555], 'lstmA_size_1': [86.98796176572928], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [47.78650670358701], 'lstmA_size_3_3': [30.222461569517197], 'n_layers': [2], 'output_dim_embedding': [120.6917296756081], 'shared_lstm_size': [22.151548644327438], 'word2vec_size': [316.0]}
18, 1.029253, 936.047283, {'batch_size': [4.341314486604794], 'dropout': [0.337014212885933], 'learning_rate': [0.0016066972701268526], 'lstmA_size_1': [19.81173976333364], 'lstmA_size_2_2': [], 'lstmA_size_2_3': [149.51634992467928], 'lstmA_size_3_3': [40.4015656898592], 'n_layers': [2], 'output_dim_embedding': [11.688501223185401], 'shared_lstm_size': [12.00936520280768], 'word2vec_size': [820.0]}
19, 1.005653, 247.022120, {'batch_size': [5.884159799901084], 'dropout': [0.12040748473172447], 'learning_rate': [0.0005797251521157946], 'lstmA_size_1': [13.375902584372358], 'lstmA_size_2_2': [62.241513714717094], 'lstmA_size_2_3': [], 'lstmA_size_3_3': [], 'n_layers': [1], 'output_dim_embedding': [39.72395263349797], 'shared_lstm_size': [49.08203606399857], 'word2vec_size': [45.0]}
Total time: 5:20:33.859706

Best parameters:{'batch_size': 4, 'dropout': 0.33016206958553795, 'learning_rate': 0.00018388129870345848, 'lstmA_size_1': 80, 'n_layers': {'lstmA_size_2_2': 23, 'n_layers': 2}, 'output_dim_embedding': 14, 'shared_lstm_size': 37, 'win_size': 4, 'word2vec_size': 852}

Next activity metrics:
              precision    recall  f1-score   support

           0      0.000     0.000     0.000        18
           1      0.885     1.000     0.939       139
           2      0.875     0.778     0.824         9
           3      0.940     1.000     0.969       156
           4      0.848     0.974     0.907       155
           5      0.598     0.428     0.499       250
           6      0.464     0.714     0.562       612
           7      0.620     0.577     0.598       605
           8      0.705     0.519     0.598       129
           9      0.766     0.755     0.761       139
          10      0.779     0.496     0.606       242
          11      0.236     0.098     0.138       133
          12      0.000     0.000     0.000        23
          13      0.000     0.000     0.000         8
          14      0.000     0.000     0.000         5
          15      0.000     0.000     0.000         9
          16      0.000     0.000     0.000         2

    accuracy                          0.627      2634
   macro avg      0.454     0.432     0.435      2634
weighted avg      0.621     0.627     0.611      2634


Next activity confusion matrix:
[[  0  18   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0 139   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   7   0   0   0   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0 156   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   1 151   0   1   1   0   0   1   0   0   0   0   0   0]
 [  0   0   0   1   9 107  76  42   0  12   1   2   0   0   0   0   0]
 [  0   0   1   3   8  31 437 100   0  11   4  17   0   0   0   0   0]
 [  0   0   0   1   6  16 215 349   0   4   4  10   0   0   0   0   0]
 [  0   0   0   3   2   3  37   4  67   0  12   1   0   0   0   0   0]
 [  0   0   0   0   1   2   8   3  20 105   0   0   0   0   0   0   0]
 [  0   0   0   0   1  13  62  23   8   5 120  10   0   0   0   0   0]
 [  0   0   0   0   0   4  83  32   0   0   1  13   0   0   0   0   0]
 [  0   0   0   1   0   2   6   2   0   0  11   1   0   0   0   0   0]
 [  0   0   0   0   0   0   8   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   3   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   5   3   0   0   0   1   0   0   0   0   0]
 [  0   0   0   0   0   1   1   0   0   0   0   0   0   0   0   0   0]]
